# Annexe A
## Glossaire du cyber citoyen

---

*50 termes essentiels pour comprendre l'IA, expliqués simplement.*

---

### A

**AGI (Artificial General Intelligence)**
Intelligence artificielle "générale" — une IA hypothétique qui serait capable de faire tout ce qu'un humain peut faire intellectuellement. N'existe pas encore. Certains pensent qu'elle arrivera dans 5 ans, d'autres dans 50, d'autres jamais.

**AI Act**
Règlement européen sur l'intelligence artificielle, adopté en 2024. Première législation complète au monde sur l'IA. Classe les systèmes IA par niveau de risque et impose des obligations croissantes.

**Alignment (alignement)**
Le défi de faire en sorte qu'une IA agisse conformément aux intentions humaines. Plus facile à dire qu'à faire : comment s'assurer qu'une IA comprend vraiment ce qu'on veut, et pas juste ce qu'on a dit ?

**API (Application Programming Interface)**
Interface qui permet à des programmes de communiquer entre eux. Quand une entreprise utilise ChatGPT dans son application, elle passe par l'API d'OpenAI.

**Attention (mécanisme d')**
Technique au cœur des transformers. Permet au modèle de "faire attention" à différentes parties du texte selon leur pertinence pour la tâche en cours.

---

### B

**Biais**
Distorsion systématique dans les résultats d'une IA, souvent héritée des données d'entraînement. Si les données contiennent des stéréotypes, l'IA les reproduira (et parfois les amplifiera).

**Black box (boîte noire)**
Système dont on voit les entrées et les sorties, mais pas le fonctionnement interne. Les grands LLM sont des boîtes noires : personne ne sait exactement pourquoi ils donnent une réponse plutôt qu'une autre.

---

### C

**Chatbot**
Programme conçu pour converser avec des humains par écrit ou par oral. ChatGPT est le chatbot le plus célèbre, mais il en existe des milliers.

**Claude**
LLM développé par Anthropic. Connu pour son approche "constitutionnelle" de la sécurité et son ton plus nuancé.

**Completion (complétion)**
Action de "compléter" un texte. C'est ce que font les LLM : vous donnez un début, ils prédisent la suite.

**Compute (calcul)**
Puissance de calcul nécessaire pour entraîner ou faire fonctionner un modèle. Entraîner GPT-4 a nécessité des milliers de GPU pendant des mois. Coût estimé : 100+ millions de dollars.

**Context window (fenêtre de contexte)**
Quantité de texte qu'un LLM peut "voir" en même temps. GPT-4 peut traiter environ 128 000 tokens (~100 000 mots). Au-delà, il "oublie".

**Copilot**
Nom donné par Microsoft à ses assistants IA intégrés dans Windows, Office, GitHub, etc. Utilise les modèles d'OpenAI.

---

### D

**Data (données)**
Matière première de l'IA. Un LLM est entraîné sur des téraoctets de texte : livres, sites web, articles, conversations... La qualité des données détermine la qualité du modèle.

**Deep Learning (apprentissage profond)**
Sous-domaine du machine learning utilisant des réseaux de neurones à nombreuses couches. C'est la technique derrière les LLM actuels.

**Deepfake**
Contenu synthétique (image, audio, vidéo) généré par IA pour imiter une personne réelle. Peut servir à créer de faux discours politiques, de fausses vidéos compromettantes, etc.

**Diffusion (modèle de)**
Technique utilisée pour générer des images (DALL-E, Midjourney, Stable Diffusion). Part de bruit aléatoire et le "nettoie" progressivement pour créer une image cohérente.

---

### E

**Embedding**
Représentation mathématique d'un mot, d'une phrase ou d'un concept sous forme de vecteur numérique. Permet à l'IA de calculer des "distances" entre concepts.

**Emergence (émergence)**
Capacités qui apparaissent dans les grands modèles sans avoir été explicitement programmées. Par exemple, la capacité de faire des mathématiques de base ou de raisonner par analogie.

---

### F

**Fine-tuning**
Entraînement supplémentaire d'un modèle pré-entraîné sur des données spécifiques. Permet d'adapter un modèle général à une tâche particulière (médecine, droit, code...).

**Foundation model (modèle de fondation)**
Modèle pré-entraîné sur d'énormes quantités de données, qui sert de base à de nombreuses applications. GPT-4, Claude, Llama sont des modèles de fondation.

---

### G

**Gemini**
Famille de modèles IA de Google (anciennement Bard). Principal concurrent de GPT-4.

**Generative AI (IA générative)**
IA capable de créer du contenu nouveau : texte, images, musique, code, vidéo. Par opposition à l'IA "analytique" qui classe ou prédit.

**GPT (Generative Pre-trained Transformer)**
Architecture et famille de modèles d'OpenAI. GPT-3.5 alimentait ChatGPT à son lancement. GPT-4 est la version actuelle la plus puissante.

**GPU (Graphics Processing Unit)**
Processeur graphique, initialement conçu pour les jeux vidéo, reconverti pour l'entraînement des IA. NVIDIA domine ce marché.

**Guardrails (garde-fous)**
Mécanismes intégrés à une IA pour l'empêcher de produire du contenu dangereux, illégal ou nuisible. Peuvent être contournés par des techniques de "jailbreak".

---

### H

**Hallucination**
Génération par l'IA d'informations fausses présentées avec assurance comme vraies. Exemple : citer un article académique qui n'existe pas. Problème fondamental des LLM actuels.

**Human-in-the-loop**
Approche où un humain supervise et valide les décisions de l'IA. L'opposé de l'automatisation complète.

---

### I

**Inference (inférence)**
Phase d'utilisation d'un modèle déjà entraîné. Quand vous posez une question à ChatGPT, le modèle fait de l'inférence (il applique ce qu'il a appris).

---

### J

**Jailbreak**
Technique pour contourner les garde-fous d'une IA et lui faire produire du contenu normalement interdit. Course permanente entre attaquants et développeurs.

---

### L

**Llama**
Famille de modèles open source de Meta. Permet à des chercheurs et entreprises d'utiliser et modifier des LLM puissants sans passer par OpenAI ou Google.

**LLM (Large Language Model)**
Grand modèle de langage. Programme entraîné sur d'énormes quantités de texte pour prédire le mot suivant. GPT-4, Claude, Gemini, Llama sont des LLM.

---

### M

**Machine Learning (apprentissage automatique)**
Branche de l'informatique où les programmes "apprennent" à partir de données plutôt que d'être explicitement programmés. Les LLM sont une forme de machine learning.

**Mistral**
Startup française fondée en 2023 par d'anciens chercheurs de Google et Meta. Développe des LLM compétitifs. Principal champion européen de l'IA générative.

**Multimodal**
IA capable de traiter plusieurs types de médias : texte, image, audio, vidéo. GPT-4o et Gemini sont multimodaux.

---

### N

**Neural network (réseau de neurones)**
Architecture informatique inspirée (très vaguement) du cerveau humain. Composée de couches de "neurones" artificiels connectés entre eux.

---

### O

**Open source**
Logiciel dont le code est public et peut être modifié par n'importe qui. Llama de Meta est open source. GPT-4 d'OpenAI ne l'est pas (malgré le nom de l'entreprise).

**OpenAI**
Entreprise américaine créatrice de ChatGPT et GPT-4. Fondée comme organisation à but non lucratif en 2015, devenue majoritairement commerciale depuis. Partenariat stratégique avec Microsoft.

**Overfitting (surapprentissage)**
Quand un modèle mémorise ses données d'entraînement au lieu d'apprendre des patterns généraux. Résultat : excellent sur les données connues, médiocre sur les nouvelles.

---

### P

**Parameter (paramètre)**
Valeur numérique ajustée pendant l'entraînement. GPT-4 aurait ~1 700 milliards de paramètres. Plus de paramètres = modèle plus puissant (généralement).

**Pre-training (pré-entraînement)**
Phase initiale où le modèle apprend à partir d'un corpus massif de texte. Le modèle apprend les patterns du langage sans supervision spécifique.

**Prompt**
Texte que vous donnez à l'IA pour obtenir une réponse. L'art de formuler de bons prompts s'appelle le "prompt engineering".

---

### R

**RAG (Retrieval-Augmented Generation)**
Technique combinant un LLM avec une base de connaissances externe. Le modèle "récupère" des informations pertinentes avant de générer sa réponse. Réduit les hallucinations.

**RGPD (Règlement Général sur la Protection des Données)**
Règlement européen de 2018 sur la vie privée. Donne aux citoyens des droits sur leurs données : accès, rectification, effacement, portabilité.

**RLHF (Reinforcement Learning from Human Feedback)**
Technique d'entraînement où des humains évaluent les réponses de l'IA pour l'améliorer. Rend les réponses plus utiles et moins problématiques.

---

### S

**Scaling laws (lois d'échelle)**
Observation empirique : plus un modèle est grand et entraîné sur plus de données, meilleures sont ses performances. Pousse à la course aux modèles toujours plus gros.

**Stochastic parrot (perroquet stochastique)**
Expression critique pour décrire les LLM : ils répètent des patterns statistiques sans vraiment "comprendre". Inventée par les chercheuses Timnit Gebru et Emily Bender.

**Synthetic data (données synthétiques)**
Données générées par IA pour entraîner d'autres IA. Solution possible à la pénurie de données naturelles, mais pose des questions sur la qualité.

---

### T

**Temperature**
Paramètre contrôlant le caractère aléatoire des réponses. Temperature basse = réponses prévisibles. Temperature haute = réponses créatives (mais potentiellement incohérentes).

**Token**
Unité de base traitée par un LLM. Généralement un mot ou un morceau de mot. "ChatGPT" = 1-2 tokens. Les modèles facturent souvent à l'usage en tokens.

**Training (entraînement)**
Phase où le modèle apprend à partir des données. Coûte des millions de dollars pour les grands modèles. Résultat : les "poids" du réseau de neurones.

**Transformer**
Architecture de réseau de neurones inventée par Google en 2017. Révolution qui a rendu les LLM possibles. Utilise le mécanisme d'attention.

**Turing test (test de Turing)**
Proposé par Alan Turing en 1950 : si une machine peut converser sans qu'on puisse la distinguer d'un humain, peut-on dire qu'elle "pense" ? Beaucoup considèrent que GPT-4 passe ce test.

---

### Z

**Zero-shot**
Capacité d'un modèle à accomplir une tâche sans exemples spécifiques. "Traduis cette phrase en japonais" → le modèle le fait sans avoir reçu d'exemples de traduction dans le prompt.

---

*Ce glossaire évolue avec la technologie. Version de décembre 2025.*
