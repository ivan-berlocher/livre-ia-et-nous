# Chapitre 1
## L'IA n'est pas ce que vous croyez

---

### 1.1 Ni robot, ni cerveau, ni oracle

Fermez les yeux. Pensez "intelligence artificielle".

Qu'est-ce qui apparaît ?

Pour certains, c'est **Terminator** — un robot métallique aux yeux rouges, programmé pour détruire l'humanité. Pour d'autres, c'est **HAL 9000**, l'ordinateur de *2001, l'Odyssée de l'espace*, qui refuse calmement d'ouvrir les portes. D'autres encore voient un cerveau électronique, des fils et des circuits qui pensent comme nous, peut-être mieux que nous.

Oubliez tout ça.

L'IA qui est entrée dans votre vie — celle avec laquelle vous parlez peut-être tous les jours — n'est **rien de tout cela**.

- Elle n'a pas de corps.
- Elle n'a pas d'objectifs propres.
- Elle ne "veut" rien.
- Elle ne vous "comprend" pas au sens où vous comprenez votre ami.
- Elle ne "sait" pas vraiment ce qu'elle dit.

Alors qu'est-ce que c'est ?

**C'est un programme qui prédit des mots.**

C'est tout. Vraiment. Quand vous posez une question à ChatGPT, le programme calcule, statistiquement, quel est le mot le plus probable après votre question. Puis le mot suivant. Puis le suivant. Jusqu'à former une phrase, un paragraphe, une réponse.

C'est extraordinairement simple comme principe.
C'est extraordinairement puissant comme résultat.
Et c'est extraordinairement trompeur comme expérience.

---

### 1.2 Une brève histoire : de Turing à ChatGPT

L'intelligence artificielle n'est pas née en 2022. Elle a 70 ans.

**1950 — Le test de Turing**

Alan Turing, le mathématicien qui a cassé le code Enigma pendant la Seconde Guerre mondiale, pose une question simple : "Les machines peuvent-elles penser ?"

Sa réponse est pragmatique : si une machine peut converser avec un humain sans que celui-ci puisse distinguer si c'est une machine ou un autre humain, alors on peut dire qu'elle "pense" — au moins du point de vue de l'observateur.

Ce test a obsédé les chercheurs pendant des décennies.

**1956 — Naissance officielle**

Le terme "intelligence artificielle" est inventé lors d'une conférence à Dartmouth. Les chercheurs sont optimistes : ils pensent qu'en 20 ans, les machines seront aussi intelligentes que les humains.

Ils se trompent de 50 ans. Au moins.

**1960-1990 — Les montagnes russes**

L'IA traverse des cycles d'euphorie et de désillusion. On appelle les périodes de déprime les "hivers de l'IA". Les promesses ne sont pas tenues. Les financements se tarissent. Mais la recherche continue.

**1997 — Deep Blue bat Kasparov**

Un ordinateur d'IBM bat le champion du monde d'échecs. C'est un choc médiatique. Mais Deep Blue ne "réfléchit" pas — il calcule des millions de positions par seconde. Force brute, pas intelligence.

**2011 — Watson gagne à Jeopardy!**

Un autre système IBM bat les champions du jeu télévisé américain. Il comprend les questions en langage naturel, avec leurs jeux de mots et leurs subtilités. Impressionnant, mais encore très limité.

**2016 — AlphaGo bat Lee Sedol**

L'événement qui change tout. Le jeu de Go est trop complexe pour la force brute — il y a plus de positions possibles que d'atomes dans l'univers. AlphaGo, de DeepMind (Google), utilise des réseaux de neurones et apprend en jouant contre lui-même.

Il fait des coups que les experts humains ne comprennent pas. Et il gagne.

**2017 — L'attention est tout ce dont vous avez besoin**

Un article de Google introduit l'architecture "Transformer". Titre original : *Attention Is All You Need*. C'est la base technique de tout ce qui va suivre.

Presque personne ne le remarque en dehors des cercles de recherche.

**2020 — GPT-3**

OpenAI publie GPT-3, un modèle de langage avec 175 milliards de paramètres. Il peut écrire des articles, du code, des poèmes. Certains sont émerveillés. D'autres sont terrifiés. La plupart n'en ont jamais entendu parler.

**30 novembre 2022 — ChatGPT**

OpenAI rend GPT-3.5 accessible au grand public via une interface simple : un chat. N'importe qui peut essayer. Gratuitement.

En 5 jours, un million d'utilisateurs.
En 2 mois, 100 millions.

Le monde découvre l'IA.

---

### 1.3 Pourquoi novembre 2022 a tout changé

ChatGPT n'était pas une rupture technologique. GPT-3 existait depuis deux ans. Les chercheurs savaient ce que ces modèles pouvaient faire.

Ce qui a changé, c'est **l'accessibilité**.

Avant novembre 2022, pour utiliser un LLM (Large Language Model — grand modèle de langage), il fallait :
- Savoir programmer
- Avoir accès à une API
- Payer pour chaque requête
- Comprendre comment formuler des "prompts"

Après novembre 2022, il suffisait de :
- Taper une question
- Appuyer sur Entrée

C'est la différence entre l'électricité dans les laboratoires et l'électricité dans les maisons. La technologie existait. Ce qui manquait, c'était l'interrupteur.

Et soudain, tout le monde a pu allumer la lumière.

Les étudiants ont découvert qu'ils pouvaient faire rédiger leurs dissertations. Les développeurs ont découvert qu'ils pouvaient faire écrire leur code. Les écrivains ont découvert un partenaire de brainstorming infatigable. Les entreprises ont découvert un assistant qui ne dort jamais.

Et tout le monde s'est posé la même question : **"Qu'est-ce que c'est que ce truc ?"**

---

### 1.4 Les mots qui embrouillent : intelligence, apprentissage, neurone

Le problème avec l'IA, c'est le vocabulaire. On utilise des mots humains pour décrire des processus qui n'ont rien d'humain.

**"Intelligence"**

Quand on dit "intelligence artificielle", on pense à notre intelligence. La capacité de comprendre, de raisonner, de ressentir, de créer du sens.

L'IA ne fait rien de tout ça.

Elle manipule des symboles selon des règles statistiques. C'est incroyablement utile. Ce n'est pas de l'intelligence au sens où vous êtes intelligent.

Un meilleur terme serait "simulation statistique de comportement intelligent". Mais c'est moins accrocheur.

**"Apprentissage"**

Quand on dit qu'une IA "apprend", on pense à un enfant qui apprend à faire du vélo. Essais, erreurs, compréhension, maîtrise.

L'IA n'apprend pas comme ça.

Elle ajuste des millions de paramètres numériques pour minimiser une fonction d'erreur. C'est de l'optimisation mathématique. Pas de l'apprentissage au sens humain.

**"Neurone"**

Les "réseaux de neurones" n'ont rien à voir avec votre cerveau.

Le terme vient d'une analogie lointaine avec les neurones biologiques, proposée dans les années 1940. Mais un "neurone artificiel" est juste une fonction mathématique simple. Il n'y a pas de biologie là-dedans.

Votre cerveau a environ 86 milliards de neurones, connectés par des trillions de synapses, qui fonctionnent par signaux chimiques et électriques, formés par des millions d'années d'évolution.

Un réseau de neurones artificiel a des matrices de nombres qui se multiplient entre elles.

Ce n'est pas la même chose.

**"Hallucination"**

Quand l'IA invente des faits avec assurance, on dit qu'elle "hallucine". Le terme suggère un dysfonctionnement, comme si l'IA devait normalement dire la vérité et parfois dérapait.

C'est l'inverse.

L'IA génère toujours des séquences de mots statistiquement probables. Parfois, ces séquences correspondent à des faits réels. Parfois non. L'IA ne fait pas la différence. Elle ne "sait" pas ce qui est vrai.

L'hallucination n'est pas un bug. C'est le fonctionnement normal du système.

---

### 1.5 Ce que l'IA fait vraiment : prédire le mot suivant

Voici la vérité, aussi simple que surprenante :

**Tout ce que fait un LLM comme ChatGPT, c'est prédire le prochain mot.**

Quand vous tapez : "La capitale de la France est"

Le modèle calcule : quel mot a la plus forte probabilité de venir ensuite ?

Réponse : "Paris" (avec une probabilité très élevée)

Le modèle ajoute "Paris" à la séquence, puis recommence : après "La capitale de la France est Paris", quel mot vient ensuite ?

Peut-être un point. Peut-être une virgule et une précision. Le modèle choisit, ajoute, recommence.

C'est tout. Il n'y a pas de base de données de faits. Il n'y a pas de raisonnement logique. Il n'y a pas de compréhension du monde.

Il y a un système qui a vu tellement de texte pendant son entraînement qu'il peut produire des séquences de mots qui *ressemblent* à ce qu'un humain informé écrirait.

**Comment ça marche en pratique ?**

Imaginez que vous avez lu tous les livres du monde, tous les articles de Wikipédia, tous les forums, tous les sites web. Pas pour les comprendre — juste pour mémoriser les patterns. Quels mots viennent souvent après quels autres mots.

Vous remarqueriez que :
- "La capitale de la France" est très souvent suivi de "est Paris"
- "Il était une fois" est souvent suivi de mots féeriques
- "Le théorème de Pythagore" est souvent suivi d'explications mathématiques

Maintenant, imaginez qu'on vous demande de compléter des phrases. Vous ne "savez" rien vraiment — vous reproduisez des patterns que vous avez observés.

C'est ce que fait l'IA.

**Pourquoi ça marche si bien ?**

Parce que le langage humain est incroyablement structuré. Il y a des règles (grammaire), des conventions (style), des patterns (rhétorique). Un système qui capture ces patterns peut produire du texte qui semble sensé.

Et parce que la quantité de données est astronomique. GPT-4 a été entraîné sur des centaines de milliards de mots. À cette échelle, les patterns deviennent très fins, très subtils.

**Pourquoi ça échoue parfois ?**

Parce que le système ne comprend pas. Il ne vérifie pas. Il ne raisonne pas vraiment.

Si vous lui demandez quelque chose qui n'était pas dans ses données d'entraînement, il va quand même produire une réponse — en combinant des patterns qui lui semblent pertinents. Parfois, ça marche. Parfois, c'est du non-sens.

Et vous ne pouvez pas savoir à l'avance lequel des deux.

---

### Ce que vous pouvez faire

1. **Changez votre image mentale.** L'IA n'est pas un robot, pas un cerveau, pas un oracle. C'est un prédicteur de mots très sophistiqué.

2. **Méfiez-vous du vocabulaire.** Quand quelqu'un dit que l'IA "comprend", "pense", ou "sait", demandez-vous ce que ça signifie vraiment.

3. **Gardez votre esprit critique.** Ce n'est pas parce qu'une réponse semble intelligente qu'elle est vraie.

---

*Chapitre suivant : Comment fonctionne ChatGPT (version honnête)*
