# Chapitre 23
## Lexique technique démystifié

---

L'IA a son jargon.

Ce chapitre est votre dictionnaire de survie.

Gardez-le à portée de main.

---

### A

**AGI (Artificial General Intelligence)**
Intelligence artificielle générale. Une IA hypothétique qui serait capable de faire tout ce qu'un humain peut faire intellectuellement. N'existe pas encore. Peut-être n'existera jamais.

**Agent**
Un système IA capable d'effectuer des actions autonomes (pas seulement répondre à des questions). Exemple : un agent qui peut réserver un vol, envoyer un email, modifier un document.

**Algorithme**
Une suite d'instructions pour résoudre un problème. Comme une recette de cuisine, mais pour un ordinateur.

**Alignement**
Le problème de s'assurer qu'une IA fait ce qu'on veut vraiment qu'elle fasse, pas juste ce qu'on lui a dit de faire. Un des grands défis de la sécurité de l'IA.

**API (Application Programming Interface)**
Interface qui permet à un programme d'utiliser un autre programme. Vous n'utilisez pas directement le modèle GPT-4 ; vous passez par l'API d'OpenAI.

**Attention (mécanisme d')**
Technique qui permet à un modèle de "se concentrer" sur les parties pertinentes d'un texte. C'est ce qui permet aux Transformers de comprendre les relations à longue distance dans un texte.

---

### B

**Biais**
Quand un système IA donne des résultats systématiquement incorrects ou injustes pour certains groupes. Exemple : un système de recrutement qui défavorise les femmes parce qu'il a été entraîné sur des données historiques biaisées.

**Big Tech**
Les géants de la technologie : Google, Meta, Microsoft, Amazon, Apple. Parfois étendu à des acteurs chinois comme Baidu ou ByteDance.

**Blackbox (boîte noire)**
Quand on ne peut pas comprendre comment un système prend ses décisions. On voit les entrées et les sorties, mais pas ce qui se passe à l'intérieur.

---

### C

**Chatbot**
Programme qui peut avoir une conversation textuelle. ChatGPT est un chatbot très avancé.

**Claude**
Modèle de langage développé par Anthropic, concurrent de GPT. Conçu avec un accent sur la sécurité et l'alignement.

**Cloud**
Serveurs distants accessibles par Internet. Quand vous utilisez ChatGPT, vous utilisez des serveurs dans le cloud (chez Microsoft Azure).

**Cloud Act**
Loi américaine de 2018 qui permet au gouvernement US d'accéder aux données stockées par des entreprises américaines, même si les serveurs sont à l'étranger.

**Context window (fenêtre de contexte)**
La quantité de texte qu'un modèle peut "garder en mémoire" pour une conversation. GPT-4 : ~128K tokens. Claude : ~200K tokens. Plus c'est grand, plus le modèle peut travailler avec de longs documents.

**Copilot**
Nom de l'assistant IA de Microsoft, basé sur GPT d'OpenAI. Intégré dans Windows, Office, Bing, etc.

**Copyright**
Droit d'auteur. Question non résolue : qui possède les œuvres générées par IA ?

---

### D

**Data (données)**
L'information utilisée pour entraîner les modèles IA. La qualité des données détermine largement la qualité du modèle.

**Deep learning (apprentissage profond)**
Technique d'apprentissage automatique utilisant des réseaux de neurones à plusieurs couches. C'est ce qui a permis les percées récentes en IA.

**Deepfake**
Contenu audio ou vidéo généré par IA qui fait dire ou faire à quelqu'un quelque chose qu'il n'a jamais dit ou fait.

**Diffusion (modèle de)**
Architecture utilisée pour la génération d'images (Stable Diffusion, DALL-E 3, Midjourney). Fonctionne en apprenant à "débruiter" une image.

**DPO (Délégué à la Protection des Données)**
Personne responsable de la conformité RGPD dans une organisation. Votre contact pour les questions de données personnelles.

---

### E

**Embedding**
Représentation numérique d'un mot, d'une phrase ou d'un document sous forme de vecteur. Permet aux machines de "comprendre" la proximité sémantique.

**Emergent behavior (comportement émergent)**
Capacités qui apparaissent dans les grands modèles sans avoir été explicitement programmées. Par exemple, les LLM qui "apprennent" à raisonner.

**Éthique de l'IA**
Domaine qui étudie les implications morales de l'IA : biais, vie privée, emploi, autonomie, etc.

---

### F

**Few-shot learning**
Capacité d'un modèle à apprendre une nouvelle tâche avec seulement quelques exemples. "Voici 3 exemples de ce que je veux, maintenant fais-le."

**Fine-tuning**
Processus d'adaptation d'un modèle pré-entraîné à une tâche spécifique en le réentraînant sur des données supplémentaires.

**Foundation model (modèle de fondation)**
Grand modèle pré-entraîné qui sert de base pour diverses applications. GPT-4, Claude, Llama sont des modèles de fondation.

---

### G

**Gemini**
Modèle de langage de Google, successeur de Bard.

**Generative AI (IA générative)**
IA capable de créer du nouveau contenu : texte, images, musique, vidéo. ChatGPT, DALL-E, Midjourney sont des IA génératives.

**GPT (Generative Pre-trained Transformer)**
Architecture de modèle d'OpenAI. GPT-3, GPT-4, GPT-4o sont des versions successives.

**GPU (Graphics Processing Unit)**
Processeur graphique. Ironiquement, ces puces conçues pour les jeux vidéo sont idéales pour l'IA. NVIDIA domine ce marché.

**Ground truth (vérité de référence)**
Les données correctes utilisées pour entraîner ou évaluer un modèle. Si la ground truth est biaisée, le modèle sera biaisé.

**Guardrails**
Protections mises en place pour empêcher un modèle de produire des contenus dangereux ou inappropriés.

---

### H

**Hallucination**
Quand un modèle génère des informations fausses présentées comme vraies. ChatGPT qui invente des citations ou des faits qui n'existent pas.

**Hugging Face**
Plateforme majeure pour les modèles IA open source. Le "GitHub de l'IA".

---

### I

**Inference (inférence)**
Le processus de faire fonctionner un modèle entraîné pour obtenir des prédictions. Quand vous posez une question à ChatGPT, le modèle fait de l'inférence.

**Intelligence artificielle (IA)**
Systèmes informatiques capables de réaliser des tâches qui nécessitent normalement l'intelligence humaine.

---

### J

**Jailbreak**
Technique pour contourner les protections d'un modèle IA et lui faire produire des contenus normalement interdits.

---

### L

**Latent space (espace latent)**
L'espace mathématique interne où un modèle représente les concepts. Difficile à visualiser, mais crucial pour comprendre comment les modèles "pensent".

**LLM (Large Language Model)**
Grand modèle de langage. Les modèles comme GPT-4, Claude, Llama qui ont été entraînés sur d'énormes quantités de texte.

**Llama**
Famille de modèles de langage open source de Meta (Facebook). Alternative ouverte aux modèles propriétaires.

---

### M

**Machine learning (apprentissage automatique)**
Technique où un programme apprend à partir de données plutôt que d'être explicitement programmé.

**Midjourney**
Service populaire de génération d'images par IA. Accessible via Discord.

**Mistral**
Startup française d'IA, créatrice de modèles de langage open source. Espoir européen face aux géants américains.

**Modèle**
Programme entraîné sur des données pour effectuer une tâche. GPT-4 est un modèle.

**Multimodal**
IA capable de traiter plusieurs types de données : texte, images, audio, vidéo. GPT-4V est multimodal (comprend les images).

---

### N

**Neural network (réseau de neurones)**
Architecture informatique inspirée du cerveau humain. Des "neurones" artificiels connectés en couches.

**NLP (Natural Language Processing)**
Traitement automatique du langage naturel. Le domaine qui permet aux machines de comprendre et générer du langage humain.

---

### O

**Open source**
Logiciel dont le code source est accessible et modifiable par tous. Llama est open source (avec restrictions), GPT-4 ne l'est pas.

**OpenAI**
Entreprise créatrice de ChatGPT, GPT-4, DALL-E. Fondée comme ONG, devenue entreprise à but lucratif plafonné.

**Overfitting (surapprentissage)**
Quand un modèle est trop bien adapté à ses données d'entraînement et généralise mal à de nouvelles données.

---

### P

**Parameter (paramètre)**
Les "réglages" internes d'un modèle. GPT-4 a ~1 trillion de paramètres. Plus il y en a, plus le modèle est potentiellement capable (et coûteux).

**Pre-training (pré-entraînement)**
Phase initiale d'entraînement d'un modèle sur de grandes quantités de données générales, avant le fine-tuning.

**Prompt**
L'instruction ou la question que vous donnez à un modèle IA. L'art du prompt est de formuler des instructions qui donnent de bons résultats.

**Prompt engineering**
L'art de formuler des prompts efficaces. Une compétence de plus en plus valorisée.

---

### R

**RAG (Retrieval-Augmented Generation)**
Technique qui combine un LLM avec une base de données externe. Permet de répondre à des questions sur des documents spécifiques.

**Reasoning (raisonnement)**
Capacité d'un modèle à suivre une logique, étape par étape. Les modèles récents (GPT-4, Claude) montrent des capacités de raisonnement émergentes.

**Red teaming**
Pratique de tester un système en essayant de le faire échouer ou de contourner ses protections. Utilisé pour améliorer la sécurité des modèles.

**Reinforcement Learning (apprentissage par renforcement)**
Technique où un modèle apprend par essai-erreur, en recevant des récompenses ou des punitions. Utilisé pour affiner les comportements des chatbots.

**RLHF (Reinforcement Learning from Human Feedback)**
Technique où des humains évaluent les réponses d'un modèle pour l'améliorer. C'est ce qui rend ChatGPT "poli" et utile.

**RGPD (Règlement Général sur la Protection des Données)**
Loi européenne sur la protection des données personnelles. Vos droits fondamentaux face aux données.

---

### S

**Scaling laws (lois de mise à l'échelle)**
Observation que les performances des modèles s'améliorent de façon prévisible quand on augmente leur taille et leurs données d'entraînement.

**Stable Diffusion**
Modèle open source de génération d'images. Peut être exécuté localement, contrairement à DALL-E ou Midjourney.

**System prompt**
Instructions cachées données au modèle avant votre conversation. Définit le comportement, la personnalité, les limites.

---

### T

**Temperature**
Paramètre qui contrôle la "créativité" d'un modèle. Température basse = réponses prévisibles. Température haute = réponses plus variées (mais parfois incohérentes).

**Token**
Unité de base du texte pour un LLM. Environ 0,75 mot en anglais, variable en français. Les modèles comptent en tokens, pas en mots.

**Training (entraînement)**
Processus par lequel un modèle apprend à partir de données. Peut prendre des mois et coûter des millions de dollars pour les grands modèles.

**Transformer**
Architecture de réseau de neurones qui a révolutionné le NLP. Le "T" de GPT. Utilise le mécanisme d'attention.

---

### V

**Vector database (base de données vectorielle)**
Base de données optimisée pour stocker et rechercher des embeddings. Essentielle pour les systèmes RAG.

---

### W

**Weights (poids)**
Les valeurs numériques qui définissent un modèle entraîné. "Télécharger les weights" = télécharger le modèle.

**Whisper**
Modèle de transcription audio d'OpenAI. Peut transcrire et traduire de l'audio en texte.

---

### Z

**Zero-shot**
Capacité d'un modèle à effectuer une tâche sans aucun exemple préalable. "Fais ceci" sans montrer comment.

---

### Ce que vous pouvez faire

1. **Gardez ce lexique accessible.** Consultez-le quand vous rencontrez un terme inconnu.

2. **N'ayez pas peur du jargon.** Derrière chaque terme compliqué, il y a un concept souvent simple.

3. **Utilisez ces termes.** Plus vous les utilisez, plus ils deviennent naturels.

---

*Chapitre suivant : Conclusion — Le citoyen augmenté*
